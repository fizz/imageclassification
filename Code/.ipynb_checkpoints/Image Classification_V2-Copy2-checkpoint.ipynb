{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data1/train'\n",
    "validation_data_dir = 'data1/validation'\n",
    "test_data_dir = 'data2/test'\n",
    "\n",
    "nb_train_samples = 40\n",
    "nb_validation_samples = 8\n",
    "nb_test_samples=12\n",
    "\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Conv2D(32, (3, 3), input_shape=(3, img_width, img_height)))\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "Found 8 images belonging to 2 classes.\n",
      "Found 3 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdullah.alkhaled/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/Users/abdullah.alkhaled/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=40, validation_data=<keras.pre..., validation_steps=8, epochs=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 2/40 [>.............................] - ETA: 30s - loss: 0.7452 - acc: 0.5625 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 2/10\n",
      " 2/40 [>.............................] - ETA: 23s - loss: 0.6431 - acc: 0.7500 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 3/10\n",
      " 2/40 [>.............................] - ETA: 23s - loss: 0.5467 - acc: 0.6094 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 4/10\n",
      " 2/40 [>.............................] - ETA: 25s - loss: 0.5628 - acc: 0.6562 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 5/10\n",
      " 2/40 [>.............................] - ETA: 27s - loss: 0.6059 - acc: 0.6719 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 6/10\n",
      " 2/40 [>.............................] - ETA: 27s - loss: 0.5527 - acc: 0.7812 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 7/10\n",
      " 2/40 [>.............................] - ETA: 24s - loss: 0.4062 - acc: 0.9531 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 8/10\n",
      " 2/40 [>.............................] - ETA: 24s - loss: 1.5433 - acc: 0.4219 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 9/10\n",
      " 2/40 [>.............................] - ETA: 24s - loss: 0.5719 - acc: 0.7969 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 10/10\n",
      " 2/40 [>.............................] - ETA: 25s - loss: 0.5036 - acc: 0.8438 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples)\n",
    "\n",
    "model.save_weights('modelsmall.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdullah.alkhaled/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:3: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  app.launch_new_instance()\n",
      "/Users/abdullah.alkhaled/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `predict_generator` call to the Keras 2 API: `predict_generator(<keras.pre..., steps=12)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testgenerator\n",
      "\n",
      "<keras.preprocessing.image.DirectoryIterator object at 0x11689eb70>\n",
      "\n",
      "\n",
      "predictions\n",
      "\n",
      "[[ 0.58640146  0.4135986 ]\n",
      " [ 0.39852634  0.60147363]\n",
      " [ 0.54942369  0.45057628]]\n",
      "train generator class indices\n",
      "{'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(\n",
    "               test_generator,\n",
    "               val_samples=nb_test_samples)\n",
    "\n",
    "# x = test_generator.filename\n",
    "print (\"testgenerator\\n\")\n",
    "print (test_generator)\n",
    "print (\"\\n\")\n",
    "print (\"predictions\\n\")\n",
    "print (predictions)\n",
    "\n",
    "print (\"train generator class indices\")\n",
    "print (train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
